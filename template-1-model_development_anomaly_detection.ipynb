{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9376da95-28a9-4159-ac34-5b3902062f1f",
   "metadata": {},
   "source": [
    "# Anomaly Detection using Computer Vision\n",
    "\n",
    "The purpose of anomaly detection via computer vision is to identify and flag instances in visual data that deviate significantly from what is considered normal or expected. *Anomalies*, also known as *outliers*, are data points or patterns that differ substantially from the majority of the data, either due to errors, defects, fraud, or any other unusual circumstances. Anomaly detection in computer vision involves leveraging machine learning and image processing techniques to automatically identify such anomalies in images or videos.\n",
    "\n",
    "Some common applications and use-cases for anomaly detection via computer vision include:\n",
    "\n",
    "**Quality Control and Defect Detection**: In manufacturing industries, computer vision can be used to inspect products for defects, such as scratches, dents, or missing parts. Any products that don't meet the expected standards can be flagged as anomalies.\n",
    "\n",
    "**Security and Surveillance**: Anomaly detection is used in security systems to detect unusual activities in surveillance videos. This could involve identifying unauthorized personnel in restricted areas, unusual object placement, or abnormal behavior patterns.\n",
    "\n",
    "**Medical Imaging**: Medical imaging technologies like X-rays, MRIs, and CT scans can be used to detect anomalies in human tissues or organs. This can help in early detection of diseases or abnormalities.\n",
    "\n",
    "**Predictive Maintenance**: In industrial settings, computer vision can monitor equipment and machinery for signs of wear and tear. Anomalies in machine behavior can be indicative of potential breakdowns, allowing for preemptive maintenance.\n",
    "\n",
    "**Traffic Monitoring**: Anomaly detection in traffic monitoring can identify unusual traffic patterns, accidents, or congestion in real time, enabling better traffic management.\n",
    "\n",
    "**Environmental Monitoring**: In environmental monitoring, computer vision can detect unusual behavior in natural habitats, such as identifying changes in animal behavior or spotting forest fires.\n",
    "\n",
    "**Agriculture**: Computer vision can help detect anomalies in crops, such as identifying plant diseases or pest infestations.\n",
    "\n",
    "The main advantage of using computer vision for anomaly detection is its ability to process large volumes of visual data quickly and consistently, allowing for the detection of anomalies in real time. It reduces the need for manual inspection and can catch anomalies that might be missed by human observers. However, setting up effective anomaly detection systems requires careful training of machine learning models and robust validation to minimize false positives and false negatives.\n",
    "\n",
    "In this notebook, we go through the process of applying anomaly detection for the purposes of quality control and defect detection (use-case one)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6657ab5c-7f3e-4380-8804-d661b3664b67",
   "metadata": {},
   "source": [
    "## Introduction to Anomalib\n",
    "\n",
    "There are several frameworks and libraries available for implementing anomaly detection using computer vision techniques like OpenCV, Scikit-image, Mahotas, Detectron2 and many others. In this notebook we use [Anomalib](https://github.com/openvinotoolkit/anomalib/tree/main), a comprehensive deep learning library designed to serve as a hub for state-of-the-art anomaly detection algorithms. \n",
    "\n",
    "The library is particularly geared towards image-based anomaly detection, with the primary goal of identifying anomalous images or abnormal pixel regions within images in a dataset. It is particularly well suited for our purposes because it offers a collection of ready-to-use implementations while also supports the implementation of custom models. Some of the key features of Anomalib include:\n",
    "\n",
    "* The largest public collection of ready-to-use deep learning anomaly detection algorithms and benchmark datasets.\n",
    "* [PyTorch Lightning](https://www.pytorchlightning.ai/) based model implementations to reduce boilerplate code and limit the implementation efforts to the bare essentials.\n",
    "* All models can be exported to [OpenVINO](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html) Intermediate Representation (IR) for accelerated inference on intel hardware.\n",
    "* A set of inference tools for quick and easy deployment of the standard or custom anomaly detection models.\n",
    "\n",
    "Let's start by importing all the classes and functions from PyTorch Lightning and Anomalib that we'll need in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce022bb-9248-43f4-b366-15cd6de0b844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83b2ef2-ef9b-43a3-b057-7eeef7815562",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from anomalib.config import get_configurable_parameters\n",
    "from anomalib.data import get_datamodule\n",
    "from anomalib.models import get_model\n",
    "from anomalib.pre_processing.transforms import Denormalize\n",
    "from anomalib.utils.callbacks import LoadModelCallback\n",
    "from anomalib.utils.callbacks import get_callbacks\n",
    "from anomalib.data.utils import read_image\n",
    "\n",
    "from anomalib.deploy import OpenVINOInferencer\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63c9bb4-fe7d-4aff-9629-48b51ecedc46",
   "metadata": {},
   "source": [
    "Anomalib provides ready implementation for a wide range of models like CFA, CFlow, FastFlow, GANomaly, PaDiM and more. Each model has its own `config.yaml` configuration file, which contains data, model and training configurable parameters, and is specific for the model and the corresponding dataset.\n",
    "\n",
    "In this notebook we use [PaDiM](https://arxiv.org/abs/2011.08785): a Patch Distribution Modeling Framework for Anomaly Detection and Localization. The project already contains the relevant configuration file for this model - `padim_config.yaml`. PaDiM is a patch based algorithm. It relies on a pre-trained CNN feature extractor. The image is broken into patches and embeddings are extracted from each patch using different layers of the feature extractors.\n",
    "\n",
    "Let's process it and print its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3ed596-d39d-40f0-809c-18f9923e9128",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "\n",
    "config_file = os.path.join(current_directory, \"padim_config.yaml\")\n",
    "\n",
    "with open(file=config_file, mode=\"r\", encoding=\"utf-8\") as file:\n",
    "    print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a88b54a-d40c-4132-a3ea-d12861d93412",
   "metadata": {},
   "source": [
    "You can notice above that the file also contains settings specific to the location and format of the training data. This leads us to the dataset we use in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f6a6a1-1a64-48ae-9ffc-3b2719d8c0a5",
   "metadata": {},
   "source": [
    "## MVTecAD Anomaly Detection Dataset\n",
    "\n",
    "The [MVTec AD dataset](https://openaccess.thecvf.com/content_CVPR_2019/papers/Bergmann_MVTec_AD_--_A_Comprehensive_Real-World_Dataset_for_Unsupervised_Anomaly_CVPR_2019_paper.pdf) is designed for evaluating anomaly detection methods in industrial inspection. It includes 5000+ high-res images grouped into 15 object and texture categories. Categories have defect-free training images and test images with defects. Two main metrics are Detection AUROC and Segmentation AUROC. Detection methods produce anomaly scores for test images, while segmentation methods provide anomaly probabilities for each pixel. Segmentation's performance is evaluated by comparing its region overlap with ground truth, and an independent metric called ROC AUC.\n",
    "\n",
    "For this notebook we focus on the defects on metal nuts category. We start by parsing the model configuration, and overriding some of the default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a163ef5a-4c1b-499f-b5d6-5cd78fd4ce7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = get_configurable_parameters(config_path=config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90efbfb9-f295-4260-905b-95faad19a4ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Focus on the metal nut category\n",
    "config.dataset.category=\"metal_nut\"\n",
    "\n",
    "# Configure the data loader\n",
    "config.dataset.num_workers=0\n",
    "config.dataset.train_batch_size=16\n",
    "config.dataset.test_batch_size=16\n",
    "\n",
    "# Set the seed for reproducibility purposes\n",
    "config.project.seed=1234\n",
    "\n",
    "# Set the output path\n",
    "config.project.path=\"padim/mvtec/mteal_nut/run\"\n",
    "\n",
    "# We set the optimiser to OpenVINO\n",
    "config.optimization.export_mode = \"openvino\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747b1f26-3c88-486e-bddf-a174613c9017",
   "metadata": {},
   "source": [
    "The MVTecAD dataset is quite large. Trying to store it in DFS or Git would be impractical. \n",
    "Instead, we can use [Domino Datasets](https://docs.dominodatalab.com/en/latest/user_guide/0a8d11/datasets/), which are ideally suited for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b98a2b4-691d-406c-9c12-2573c044cd08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#determine dataset path and set\n",
    "if os.environ['DOMINO_WORKING_DIR'] == '/mnt/code':\n",
    "    config.dataset.path = os.path.join(os.environ[\"DOMINO_DATASETS_DIR\"], os.environ[\"DOMINO_PROJECT_NAME\"])\n",
    "else:\n",
    "    config.dataset.path = os.path.join(os.environ[\"DOMINO_DATASETS_DIR\"], \"local\", os.environ[\"DOMINO_PROJECT_NAME\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d083038-0ceb-4213-92d6-a73cd7dd0521",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get Anomaly Datamodule\n",
    "datamodule = get_datamodule(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688b2b8b-3c25-42c0-adb1-655ad4119374",
   "metadata": {},
   "source": [
    "We now need to download about 5.26 GB of data and unpack it. This may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e6576e-6b54-417d-87bd-cf7a16f1d4b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datamodule.prepare_data()\n",
    "\n",
    "# Download the dataset if not available\n",
    "\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e81fb7a-c79d-4f92-bbca-101188d7bf32",
   "metadata": {},
   "source": [
    "Let's look at the dataset keys to confirm everything is in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e92cf91-3368-40e7-aebb-084826090370",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i, data = next(enumerate(datamodule.val_dataloader()))\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a43da6-56be-44b7-b34d-d058e75720b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's plot some of the training images to get a sense of what data we are dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9d31f1-7658-446c-ac60-9a06260873cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_path = os.path.join(config.dataset.path, \"metal_nut\", \"train\", \"good\")\n",
    "\n",
    "f, axarr = plt.subplots(2,2)\n",
    "axarr[0,0].imshow(read_image(path=os.path.join(image_path, \"000.png\")))\n",
    "axarr[0,1].imshow(read_image(path=os.path.join(image_path, \"001.png\")))\n",
    "axarr[1,0].imshow(read_image(path=os.path.join(image_path, \"002.png\")))\n",
    "axarr[1,1].imshow(read_image(path=os.path.join(image_path, \"003.png\")));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f89f62-2cb8-4afb-bbed-d06e0579e862",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b733395-7c5a-441c-a532-be29efdd33f2",
   "metadata": {},
   "source": [
    "Now lets load the model using the configuration and also get the base callbacks for lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3c94c7-d766-4284-b613-8f91e9256bd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = get_model(config)\n",
    "callbacks = get_callbacks(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effab031-ce12-4d92-9f61-326638b2a2a9",
   "metadata": {},
   "source": [
    "We can now train the PaDiM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e14939-af46-4852-8a16-290aa4b1e47b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(**config.trainer, callbacks=callbacks)\n",
    "trainer.fit(model=model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad005edf-c3b2-4855-95b1-0e6f18d5bc8b",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c9d2c3-5b1f-4528-8593-4445ab9834de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = os.path.join(config.project.path, \"weights\", \"openvino\", \"model.bin\")\n",
    "model_metadata = os.path.join(config.project.path, \"weights\", \"openvino\", \"metadata.json\")\n",
    "\n",
    "print(\"Our model was successfully trained and stored in:\", model_path)\n",
    "print(\"Model metadata is location in: \", model_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc15dc66-758f-4a28-8137-3880f14de671",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Now let's see how we can use the trained model to do some inference.\n",
    "\n",
    "First, let's make sure that the *model.bin* and corresponding metadata file exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eeca01-edfb-452b-8d2f-e26f789835e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(os.path.isfile(model_path), os.path.isfile(model_metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab1385d-9dd7-4a65-b231-9f48d206fbf8",
   "metadata": {},
   "source": [
    "Next, let's see some images that exhibit anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd2852d-1c17-49d3-afc6-5193fcaca953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_path = os.path.join(config.dataset.path, \"metal_nut\", \"test\")\n",
    "\n",
    "f, axarr = plt.subplots(2,2)\n",
    "axarr[0,0].imshow(read_image(path=os.path.join(image_path, \"bent/000.png\")))\n",
    "axarr[0,1].imshow(read_image(path=os.path.join(image_path, \"color/000.png\")))\n",
    "axarr[1,0].imshow(read_image(path=os.path.join(image_path, \"flip/000.png\")))\n",
    "axarr[1,1].imshow(read_image(path=os.path.join(image_path, \"scratch/000.png\")));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2093b2fe-7de1-4911-86f3-d88955f3a166",
   "metadata": {},
   "source": [
    "The [OpenVINO Runtime](https://docs.openvino.ai/2023.0/openvino_docs_OV_UG_OV_Runtime_User_Guide.html) is a collection of C++ libraries with bindings for C and Python. It offers a unified API for deploying inference solutions on various platforms. This API allows you to load models in different formats like IR, TensorFlow, TensorFlow Lite, ONNX, or PaddlePaddle and run them on your preferred devices.\n",
    "\n",
    "The OpenVINO Runtime provides various inference modes to ensure efficient hardware usage in different scenarios. The simplest mode is the single-device mode, where a single device handles the entire inference workload. This mode is compatible with a variety of Intel hardware, utilizing specialized plugins within the Runtime library for optimized performance. To learn more about the supported devices and how to utilize them, consult the [guide on inference devices](https://docs.openvino.ai/2023.0/openvino_docs_OV_UG_Working_with_devices.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59b77cc-b8fc-4116-bb13-96875615d8b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inferencer = OpenVINOInferencer(\n",
    "    path=model_path, \n",
    "    metadata=model_metadata, \n",
    "    device=\"CPU\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84575ffb-7c23-48ef-b0aa-a0bc50ecd3e9",
   "metadata": {},
   "source": [
    "Let's try one of the anomalous images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc6edaf-e9d8-4a37-ada5-8be916bb1c5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_path = os.path.join(config.dataset.path, \"metal_nut\", \"test\", \"bent\", \"000.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d4d33-b8ec-4690-a900-943e0cd06148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = inferencer.predict(image=image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a43bc6-e74a-419e-9e6b-e008a4a69cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Prediction score: \", predictions.pred_score)\n",
    "print(\"Prediction label: \", predictions.pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cab11f-509a-4bcf-84fb-f52ba5f909cb",
   "metadata": {},
   "source": [
    "Let's look at the image that was just scored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ab2b15-47f6-459f-8139-82c9dcc25555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(predictions.image);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76b1f7c-0134-41d4-8110-478cf620147b",
   "metadata": {},
   "source": [
    "Anomalib also provides an Anomaly Map Generator for the PaDiM model implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84844b1d-065d-4a4e-aee5-502c798cafab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(predictions.anomaly_map);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fce8ef6-b860-4d09-a7f6-8356f656f34b",
   "metadata": {},
   "source": [
    "Recall that PaDIM is a patch based algorithm. This is generally a segmentation type of model, so we can also visualise the specific areas of the image that exhibit anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531ac56f-6818-4c18-8f46-fc6d7d398cd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(predictions.segmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938ffd29-cbbc-4370-b38d-b74cc2a2efb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dca-init": "true",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
